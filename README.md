# Multimodal Vision-Language Pipeline (FastAPI + React)

This project is a **multimodal vision-language pipeline** built using **FastAPI** for the backend and **React** for the frontend. It combines **computer vision** and **natural language processing** to support:

- ğŸ–¼ï¸ **Image Captioning** â†’ Generate natural language captions for images using BLIP.
- â“ **Visual Question Answering (VQA)** â†’ Ask questions about an image and get contextual answers.
- ğŸ” **Image â†” Text Retrieval** â†’ Retrieve images from a dataset using text queries with CLIP embeddings.

The project is structured into two parts: a **FastAPI backend** providing REST APIs, and a **React frontend** offering a user-friendly interface.

---

## ğŸ“‚ Project Structure
```
multimodal_vlp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # FastAPI app with REST endpoints
â”‚   â”œâ”€â”€ pipeline.py         # VisionLanguagePipeline class (load models, inference)
â”‚   â”œâ”€â”€ utils.py            # helper functions (image loading, embedding store)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx         # React frontend
â”‚   â”‚   â”œâ”€â”€ components/     # Components: Captioning, VQA, Retrieval
â”‚   â”‚   â””â”€â”€ api.js          # Axios API helpers
â”‚   â””â”€â”€ public/
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation Guide

### ğŸ”¹ Backend (FastAPI)
1. Navigate to the backend folder:
   ```bash
   cd backend
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate   # Linux/Mac
   .\.venv\Scripts\activate   # Windows
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Run the backend server:
   ```bash
   uvicorn app:app --reload --host 0.0.0.0 --port 8000
   ```

Backend will be available at: **http://localhost:8000**

---

### ğŸ”¹ Frontend (React)
1. Navigate to the frontend folder:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the development server:
   ```bash
   npm run dev
   ```

Frontend will be available at: **http://localhost:5173**

---

## ğŸš€ Usage
- Open the frontend in your browser.
- **Captioning**: Upload an image â†’ get a generated caption.
- **VQA**: Upload an image + ask a question â†’ get an answer.
- **Retrieval**: Enter a text query â†’ retrieve the most relevant images.

---

## ğŸ› ï¸ Technologies Used
- **Backend**: FastAPI, Transformers (Hugging Face), PyTorch
- **Frontend**: React, Axios, Vite

---

## ğŸ“Œ Notes
- Pre-trained models (BLIP, CLIP) are automatically downloaded from Hugging Face on first run.
- For large-scale retrieval, embeddings can be indexed using FAISS or another vector database.
- Dockerfiles are included for containerized deployment.
